{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 2728,
     "status": "ok",
     "timestamp": 1605742013934,
     "user": {
      "displayName": "Daisuke Kuwabara",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggk_BIVN1dQr4gk1J35io6zCkXBnptTl-DmPum6=s64",
      "userId": "03474816286936766149"
     },
     "user_tz": -540
    },
    "id": "AIjhOHR8V61F"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import optuna.integration.lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 961
    },
    "executionInfo": {
     "elapsed": 29810,
     "status": "ok",
     "timestamp": 1605742041038,
     "user": {
      "displayName": "Daisuke Kuwabara",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggk_BIVN1dQr4gk1J35io6zCkXBnptTl-DmPum6=s64",
      "userId": "03474816286936766149"
     },
     "user_tz": -540
    },
    "id": "s7EYIjP7XThQ",
    "outputId": "a8537eef-ab99-4cb9-dcfc-ee2af47b52b0"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:/Users/daisu/OneDrive/Desktop/GCI/Input/train.csv\")\n",
    "test = pd.read_csv(\"C:/Users/daisu/OneDrive/Desktop/GCI/Input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29802,
     "status": "ok",
     "timestamp": 1605742041039,
     "user": {
      "displayName": "Daisuke Kuwabara",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggk_BIVN1dQr4gk1J35io6zCkXBnptTl-DmPum6=s64",
      "userId": "03474816286936766149"
     },
     "user_tz": -540
    },
    "id": "EZQYjf67XWNY",
    "outputId": "002fb5b4-3a64-425e-a532-23a00fbd4110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index numbers: 171202, Column numbers: 51\n",
      "Index numbers: 61500, Column numbers: 51\n"
     ]
    }
   ],
   "source": [
    "print(f\"Index numbers: {train.shape[0]}, Column numbers: {train.shape[1]}\")\n",
    "print(f\"Index numbers: {test.shape[0]}, Column numbers: {train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code binary value \n",
    "\n",
    "for df in [train, test]:\n",
    "    df.replace({'CODE_GENDER': {'M': 0, 'F': 1}}, inplace=True)\n",
    "    df.replace({'FLAG_OWN_CAR': {'N': 0, 'Y': 1}}, inplace=True)\n",
    "    df.replace({'FLAG_OWN_REALTY': {'N': 0, 'Y': 1}}, inplace=True)\n",
    "    df.replace({'NAME_CONTRACT_TYPE': {'Cash loans': 0, 'Revolving loans': 1}}, inplace=True)\n",
    "    \n",
    "    # Replace XNA by NaN\n",
    "    df.replace('XNA', np.nan, inplace=True)\n",
    "    \n",
    "    # Replace outliers by NaN\n",
    "    df.replace({'DAYS_EMPLOYED': {365243: np.nan}}, inplace=True)\n",
    "    df.replace({'DAYS_LAST_PHONE_CHANGE': {0: np.nan}}, inplace=True)\n",
    "\n",
    "train.replace({'OWN_CAR_AGE': {64: np.nan, 65: np.nan, 91: np.nan}}, inplace=True)\n",
    "test.replace({'OWN_CAR_AGE': {64: np.nan, 69: np.nan, 91: np.nan}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features\n",
    "\n",
    "for df in [train, test]:\n",
    "    # YEARS_AMT\n",
    "    df['YEARS_AMT'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    # AMT_INCOME_RATE\n",
    "    df['AMT_INCOME_RATE'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    # GOODS_CREDIT_RATE\n",
    "    df['GOODS_CREDIT_RATE'] = df['AMT_GOODS_PRICE'] / df['AMT_CREDIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused features\n",
    "for df in [train, test]:\n",
    "    df.drop([\"FLAG_MOBIL\", \"FLAG_EMP_PHONE\", \"FLAG_CONT_MOBILE\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "executionInfo": {
     "elapsed": 29003,
     "status": "ok",
     "timestamp": 1605742041040,
     "user": {
      "displayName": "Daisuke Kuwabara",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggk_BIVN1dQr4gk1J35io6zCkXBnptTl-DmPum6=s64",
      "userId": "03474816286936766149"
     },
     "user_tz": -540
    },
    "id": "cYI-urBcXey6",
    "outputId": "37c6b3d4-9f9f-4248-ba27-a821040c6581"
   },
   "outputs": [],
   "source": [
    "#One-hot-Encoding\n",
    "df_all = pd.concat([train, test])\n",
    "df_ohe = pd.get_dummies(df_all)\n",
    "\n",
    "train = df_ohe[:171202]\n",
    "test = df_ohe[171202:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, 2:].values\n",
    "y = train.iloc[:, 1].values\n",
    "test_X = test.iloc[:, 2:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb1 = XGBClassifier(max_depth=5,\n",
    "                    min_child_weight=6,\n",
    "                    subsample=0.9, \n",
    "                    colsample_bytree=0.5, \n",
    "                    learning_rate=0.02943370997880096,\n",
    "                    n_estimators=941,\n",
    "                    tree_method='gpu_hist',\n",
    "                    random_state=0)\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb1 = LGBMClassifier(random_state=0,\n",
    "                     objective='binary', \n",
    "                     metric='auc',\n",
    "                     boosting_type='gbdt',\n",
    "                     feature_pre_filter=False, \n",
    "                     lambda_l1=0.7050822301496653, \n",
    "                     lambda_l2=0.0058386827559236834, \n",
    "                     num_leaves=4, \n",
    "                     feature_fraction=0.41600000000000004, \n",
    "                     bagging_fraction=0.8300542479068319, \n",
    "                     bagging_freq=1, \n",
    "                     min_child_samples=20,\n",
    "                     n_estimators=1440)\n",
    "\n",
    "lgb2 = LGBMClassifier(random_state=0, \n",
    "                      metric='auc', \n",
    "                      n_estimators=857, \n",
    "                      max_depth=5, \n",
    "                      min_child_weight=14, \n",
    "                      colsample_bytree=0.5, \n",
    "                      learning_rate=0.045281028617681414, \n",
    "                      lambda_l1=2.5624353984127566e-07, \n",
    "                      lambda_l2=4.758516522619317)\n",
    "\n",
    "xgb2 = XGBClassifier(random_state=0, \n",
    "                     n_estimators=1838, \n",
    "                     objective='binary:logistic', \n",
    "                     tree_method='gpu_hist', \n",
    "                     max_depth=5, \n",
    "                     min_child_weight=2, \n",
    "                     subsample=0.7, \n",
    "                     colsample_bytree=0.5, \n",
    "                     learning_rate=0.02013171044857669)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.41600000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41600000000000004\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7050822301496653, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7050822301496653\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8300542479068319, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8300542479068319\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0058386827559236834, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0058386827559236834\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:19:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "lgb1.fit(X, y)\n",
    "lgb2.fit(X, y)\n",
    "xgb1.fit(X, y)\n",
    "xgb2.fit(X, y)\n",
    "\n",
    "lgb1_pred = lgb1.predict_proba(test_X)\n",
    "lgb2_pred = lgb2.predict_proba(test_X)\n",
    "xgb1_pred = xgb1.predict_proba(test_X)\n",
    "xgb2_pred = xgb2.predict_proba(test_X)\n",
    "\n",
    "pred = ((xgb1_pred[:, 1] + lgb1_pred[:, 1] + xgb2_pred[:, 1] + lgb2_pred[:, 1])/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/daisu/OneDrive/Desktop/\"\n",
    "\n",
    "submission = pd.read_csv(path + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"TARGET\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('C:/Users/daisu/OneDrive/Desktop/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNz9HMXmu8VuMdD4CTdT9Et",
   "name": "Untitled0.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
