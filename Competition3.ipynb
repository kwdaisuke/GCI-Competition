{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sy\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import  LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = pd.read_csv(\"C:/Users/daisu/OneDrive/Desktop/GCI/drive-download-20201224T003704Z-001/stores.csv\", )\n",
    "genres = pd.read_csv(\"C:/Users/daisu/OneDrive/Desktop/GCI/drive-download-20201224T003704Z-001/genres.csv\", )\n",
    "goods = pd.read_csv(\"C:/Users/daisu/OneDrive/Desktop/GCI/drive-download-20201224T003704Z-001/goods.csv\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_genre=pd.merge(goods, genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"C:/Users/daisu/OneDrive/Desktop/GCI/drive-download-20201224T003704Z-001/train.csv\")\n",
    "test_df  =pd.read_csv(\"C:/Users/daisu/OneDrive/Desktop/GCI/drive-download-20201224T003704Z-001/test.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_df, good_genre)\n",
    "train_df = pd.merge(train_df, stores)\n",
    "test_df = pd.merge(test_df, good_genre)\n",
    "test_df = pd.merge(test_df, stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"yy_mm_dd\"] = pd.to_datetime(train_df['yy_mm_dd'],format='%y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.index = train_df.yy_mm_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df[\"month\"] = train_df.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"year\"] = train_df.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_sold_month = train_df.groupby(by = [train_df.index.month, train_df.index.year]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_sold_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "units_sold_month.index.names = [\"month\", \"year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "units_sold_month = units_sold_month.rename(columns={\"units_sold_day\": \"units_sold_month\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_sold_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_sold_month.drop(\"price store_id goods_id goods_genre_id num_month\".split(\" \"), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "units_sold_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_df, units_sold_month, on = [\"month\", \"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.goods_genre_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(\"yy_mm_dd price store_id units_sold_day goods_id goods_genre_id num_month year month\".split(\" \"), axis=1, inplace=True)\n",
    "test_df.drop(\"index store_id goods_id goods_genre_id\".split(\" \"), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.hist(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"Original size of train_df: {train_df.shape}\")\n",
    "print(f\"Original size of test_df: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# encoder = LabelEncoder()\n",
    "\n",
    "# train_df.goods_name = encoder.fit_transform(train_df.goods_name)\n",
    "# test_df.goods_name = encoder.transform(test_df.goods_name)\n",
    "\n",
    "# train_df.goods_genre_name = encoder.fit_transform(train_df.goods_genre_name)\n",
    "# test_df.goods_genre_name = encoder.transform(test_df.goods_genre_name)\n",
    "\n",
    "# train_df.store_name = encoder.fit_transform(train_df.store_name)\n",
    "# test_df.store_name = encoder.transform(test_df.store_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"# Get values which are not common in both train and test dataframe\n",
    "filter1=test_df[\"goods_name\"].isin(train_df[\"goods_name\"])\n",
    "filter2=test_df[\"goods_genre_name\"].isin(train_df[\"goods_genre_name\"])\n",
    "filter3=test_df[\"store_name\"].isin(train_df[\"store_name\"])\n",
    "\n",
    "# Filter for which are False\n",
    "goods_diff = test_df.goods_name[~filter1]\n",
    "genre_diff = test_df.goods_genre_name[~filter1]\n",
    "store_diff = test_df.store_name[~filter1]\n",
    "\n",
    "# Get distinct values\n",
    "goods_diff = np.unique(goods_diff)\n",
    "genre_diff = np.unique(genre_diff)\n",
    "store_diff = np.unique(store_diff)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"goods_diff = np.unique(goods_diff)\n",
    "genre_diff = np.unique(genre_diff)\n",
    "store_diff = np.unique(store_diff)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Replace those not in common by the name, \"others\"\n",
    "for good in test_df.goods_name:\n",
    "    if good in goods_diff_list:\n",
    "        test_df[\"goods_name\"].replace(good, \"others\", inplace=True)\n",
    "\n",
    "for genre in test_df.goods_genre_name:\n",
    "    if genre in genre_diff_list:\n",
    "        test_df[\"goods_genre_name\"].replace(genre, \"others\", inplace=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"test_df = test_df[test_df.goods_name!=\"others\"]\n",
    "test_df = test_df[test_df.goods_genre_name!=\"others\"]\n",
    "test_df = test_df[test_df.store_name!=\"others\"]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna.integration.lightgbm as lgb_o\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.datasets\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#Prepare train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "#Set data for lightGBM\n",
    "train = lgb_o.Dataset(X_train, y_train)\n",
    "test = lgb_o.Dataset(X_test, y_test)\n",
    "\n",
    "#Hyperparameter search\n",
    "params = {'objective': 'regression',\n",
    "          'metric': 'rmse',\n",
    "          'random_seed':0} \n",
    "\n",
    "gbm_o = lgb_o.train(params,\n",
    "                    train,\n",
    "                    valid_sets=test,\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose_eval=200,)\n",
    "\n",
    "y_train_pred = gbm_o.predict(X_train,num_iteration=gbm_o.best_iteration)\n",
    "y_test_pred = gbm_o.predict(X_test,num_iteration=gbm_o.best_iteration)\n",
    "\n",
    "best_params = gbm_o.params\n",
    "print(\"  Params: \")\n",
    "for key, value in best_params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "X_train, y_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Set data for lightgbm\n",
    "train = lgb.Dataset(X_train, y_train)\n",
    "\n",
    "tuner = lgb.LightGBMTunerCV(params, train, verbose_eval=100, early_stopping_rounds=100, folds=KFold(n_splits=3))\n",
    "\n",
    "# Search for the hyperparameters\n",
    "tuner.run()\n",
    "\n",
    "#Show the best parameters\n",
    "best_params = tuner.best_params\n",
    "print(\" Params: \")\n",
    "for key, value in best_params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column values which exist both in train and test dataset\n",
    "\n",
    "\n",
    "filter1 = train_df[\"goods_name\"].isin(test_df[\"goods_name\"])\n",
    "filter2=train_df[\"goods_genre_name\"].isin(test_df[\"goods_genre_name\"])\n",
    "filter3=train_df[\"store_name\"].isin(test_df[\"store_name\"])\n",
    "\n",
    "train_df= train_df[filter1&filter2&filter3]\n",
    "\n",
    "\n",
    "filter1 = test_df[\"goods_name\"].isin(train_df[\"goods_name\"])\n",
    "filter2=test_df[\"goods_genre_name\"].isin(train_df[\"goods_genre_name\"])\n",
    "filter3=test_df[\"store_name\"].isin(train_df[\"store_name\"])\n",
    "\n",
    "test_df= test_df[filter1&filter2&filter3]\n",
    "#genre_diff = train_df.goods_genre_name[filter2]\n",
    "#store_diff = train_df.store_name[filter3]\n",
    "\n",
    "# goods_diff = np.unique(goods_diff)\n",
    "# genre_diff = np.unique(genre_diff)\n",
    "# store_diff = np.unique(store_diff)\n",
    "\n",
    "# Replace those not in common by the name, \"others\"\n",
    "\n",
    "# for good in train_df.goods_name:\n",
    "#     if good in goods_diff:\n",
    "#         train_df[\"goods_name\"].replace(good, \"others\", inplace=True)\n",
    "\n",
    "# for genre in test_df.goods_genre_name:\n",
    "#     if genre in genre_diff:\n",
    "#         train_df[\"goods_genre_name\"].replace(genre, \"others\", inplace=True)\n",
    "        \n",
    "# for store in train_df.store_name:\n",
    "#     if store in store_diff:\n",
    "#         train_df[\"store\"].replace(store, \"others\", inplace=True)\n",
    "        \n",
    "# train_df = train_df[train_df.goods_genre_name!=\"others\"]\n",
    "# train_df = train_df[train_df.store_name!=\"others\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.get_dummies(test_df, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(\"yy_mm_dd\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=train_df.pop(\"units_sold_month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, output], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df\n",
    "y = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost  as xgb\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "        'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 0.9, 0.1),\n",
    "        'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 0.9, 0.1),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n",
    "        'random_state': 0,\n",
    "        'tree_method': 'gpu_hist'\n",
    "    }\n",
    "\n",
    "    xgboost = xgb.XGBRegressor(**params, n_estimators=10000)\n",
    "    xgboost= xgboost.fit(X_train, y_train, early_stopping_rounds=100, eval_metric='rmse', eval_set=[[X_test, y_test]])\n",
    "    y_pred = \n",
    "    rmse = np.sqrt(MSE(y_test, y_pred))\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "study_xgb = optuna.create_study(direction=\"minimize\")\n",
    "study_xgb.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter for CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "import numpy as np\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 50, 300),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
    "        \"random_strength\": trial.suggest_int(\"random_strength\", 0, 100),\n",
    "        \"bagging_temperature\": trial.suggest_loguniform(\n",
    "            \"bagging_temperature\", 0.01, 100.00\n",
    "        ),\n",
    "        \"od_type\": trial.suggest_categorical(\"od_type\", [\"IncToDec\", \"Iter\"]),\n",
    "        \"od_wait\": trial.suggest_int(\"od_wait\", 10, 50),\n",
    "        \"verbose\": True,\n",
    "        \"task_type\": \"GPU\"\n",
    "    }\n",
    "    categorical_cat = np.where(train_df.dtypes != np.float)[0]\n",
    "\n",
    "    gbm = cb.CatBoostRegressor(**params)\n",
    "    gbm = gbm.fit(X_train, y_train, cat_features=categorical_cat, eval_set=[(X_test, y_test)], verbose=0, early_stopping_rounds=100,plot=True)\n",
    "\n",
    "    y_pred = gbm.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_cat = optuna.create_study(direction=\"minimize\")\n",
    "study_cat.optimize(objective, n_trials=100, timeout=300)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study_cat.trials)))\n",
    "print(\"Best trial:\")\n",
    "trial = study_cat.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cat = train_df.columns.values\n",
    "categorical_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_params)\n",
    "print(study.best_value)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=5))\n",
    "study.optimize(objective_with_prune, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_cat.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trials_df = study_cat.trials_dataframe()\n",
    "trials_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# blue dot is the score of this trial and orange line show the best score.\n",
    "#Note that blue dot is not in the all trial, because we turned on pruning thus many of the trials are stopped before getting final objective value.\n",
    "#optuna.visualization.plot_optimization_history(study_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optuna.visualization.plot_intermediate_values(study_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optuna.visualization.plot_slice(study_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model(LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train_df.columns:\n",
    "    train_df[column] = train_df[column].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caution: You don't have to turn DataFrame into Numpy array\n",
    "X = train_df\n",
    "y = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape[0]/X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import BaggingRegressor\n",
    "    \n",
    "# \"\"\" Bagging meta-estimator is an ensembling algorithm that can be used for\n",
    "#     both classification (BaggingClassifier) and regression (BaggingRegressor) problems. \n",
    "#     It follows the typical bagging technique to make predictions. \n",
    "#     Following are the steps for the bagging meta-estimator algorithm:\n",
    "\n",
    "#     1. Random subsets are created from the original dataset (Bootstrapping).\n",
    "#     2. The subset of the dataset includes all features.\n",
    "#     3. A user-specified base estimator is fitted on each of these smaller sets.\n",
    "#     4. Predictions from each model are combined to get the final result.\n",
    "#     \"\"\"\n",
    "\n",
    "# bar = BaggingRegressor(tree.DecisionTreeRegressor(random_state=1))\n",
    "\n",
    "\n",
    "# from sklearn.ensemble import AdaBoostingRegressor\n",
    "# \"\"\" Adaptive boosting or AdaBoost is one of the simplest boosting algorithms. \n",
    "#     Usually, decision trees are used for modelling. \n",
    "#     Multiple sequential models are created, each correcting the errors from the last model. \n",
    "#     AdaBoost assigns weights to the observations which are incorrectly predicted and \n",
    "#     the subsequent model works to predict these values correctly.\n",
    "#     \"\"\"\n",
    "\n",
    "# abr = AdaBoostRegressor()\n",
    "\n",
    "\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# \"\"\" Gradient Boosting or GBM is another ensemble machine learning algorithm that works for\n",
    "#     both regression and classification problems. GBM uses the boosting technique, \n",
    "#     combining a number of weak learners to form a strong learner. Regression trees used as a base learner, \n",
    "#     each subsequent tree in series is built on the errors calculated by the previous tree.\"\"\"\n",
    "\n",
    "# gbr = GradientBoostingRegressor()\n",
    "\n",
    "\n",
    "# from xgboost import XGBRegressor\n",
    "# \"\"\" XGBoost (extreme Gradient Boosting) is an advanced implementation of the gradient boosting algorithm.\n",
    "#     XGBoost has proved to be a highly effective ML algorithm, extensively used in machine learning competitions and \n",
    "#     hackathons. XGBoost has high predictive power and is almost 10 times faster than the other gradient boosting techniques. It also includes a variety of regularization which reduces overfitting and improves overall performance. \n",
    "#     Hence it is also known as ‘regularized boosting‘ technique.\n",
    "#     \"\"\"\n",
    "\n",
    "# xgb = XGBRegressor()\n",
    "\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "cat = CatBoostRegressor(\n",
    " iterations= 179,\n",
    " depth = 10,\n",
    " learning_rate = 0.3291221497178803,\n",
    " random_strength = 47,\n",
    " bagging_temperature = 60.918745770482076,\n",
    " od_type = 'IncToDec',\n",
    " od_wait = 20,\n",
    ")\n",
    "\n",
    "categorical_cat = np.where(train_df.dtypes !=np.float)[0]\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "#     \"\"\"\n",
    "#     Light GBM beats all the other algorithms when the dataset is extremely large. \n",
    "#     Compared to the other algorithms, Light GBM takes lesser time to run on a huge dataset.\n",
    "#     LightGBM is a gradient boosting framework that uses tree-based algorithms and follows leaf-wise approach \n",
    "#     while other algorithms work in a level-wise approach pattern. \n",
    "#     \"\"\"\n",
    "\n",
    "categorical_list = ['goods_name', 'goods_genre_name', 'store_name']\n",
    "lgb = LGBMRegressor(objective = 'regression',\n",
    "                     metric = 'rmse',\n",
    "                     random_seed = 0,\n",
    "                     feature_pre_filter = False,\n",
    "                     lambda_l1 = 2.377982329588689e-07,\n",
    "                     lambda_l2 = 1.2825820088020978e-08,\n",
    "                     num_leaves = 256,\n",
    "                     feature_fraction = 0.6,\n",
    "                     bagging_fraction = 0.7471801931739468,\n",
    "                     bagging_freq = 7,\n",
    "                     min_child_samples = 5,\n",
    "                     categorical_features=categorical_list)\n",
    "#y_pred = lgb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bar.fit(X, y) # Bagging\n",
    "# abr.fit(X, y) # AdaBoost\n",
    "# gbr.fit(X, y) # GradientBoost\n",
    "# xgb.fit(X, y) # XGBoost\n",
    "cat.fit(X, y, cat_features=categorical_cat) # CatBoost\n",
    "lgb.fit(X, y, categorical_feature=categorical_list) # LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(cat.feature_importances_, index=train_df.columns, columns=['importance'])\n",
    "display(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(lgb.feature_importances_, index=train_df.columns, columns=['importance'])\n",
    "display(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pred_dict ={}\n",
    "# for i, booster in enumerate(boosters):\n",
    "#     y_pred = booster.predict(X_test, num_iteration=best_iteration)\n",
    "#     pred_dict.setdefault(i, y_pred)\n",
    "#     rmse = np.sqrt(MSE(y_test, y_pred))\n",
    "#     print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse = np.sqrt(MSE(y_test, y_pred))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(regressor.feature_importances_, index=test_df.columns, columns=['importance'])\n",
    "display(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "importance.plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-Gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon as ag\n",
    "from autogluon import TabularPrediction as task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = task.Dataset(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir = \"C:/Users/daisu/OneDrive/Desktop/GCI/drive-download-20201224T003704Z-001/model\"\n",
    "predictor = task.fit(train_data=train_data, label=\"units_sold_month\", output_directory=dir, problem_type=\"regression\", eval_metric=\"root_mean_squared_error\", AG_args_fit={\"use_gpu\":True} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(X_test)\n",
    "print(f\"Predictions: {y_pred}\")\n",
    "perf = predictor.evaluate_predictions(y_true = y_test, y_pred = y_pred, auxiliary_metrics = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(X_test)\n",
    "print(f\"Predictions: {y_pred}\")\n",
    "perf = predictor.evaluate_predictions(y_true = y_test, y_pred = y_pred, auxiliary_metrics = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor.feature_importance(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictor.get_model_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.predict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data type into categorical \n",
    "for feature in test_df.columns:\n",
    "    test_df[feature] = pd.Series(test_df[feature], dtype=\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat_pred = cat.predict(test_df)\n",
    "lgb_pred = lgb.predict(test_df)\n",
    "cat_lgb = (cat_pred+lgb_pred)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\"cat\":cat_pred, \"lgb\":lgb_pred, \"cat_lgb\": cat_lgb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict ={}\n",
    "for i, booster in enumerate(boosters):\n",
    "    result = booster.predict(test_df, num_iteration=best_iteration)\n",
    "    pred_dict.setdefault(i, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=0\n",
    "for i in pred_dict.keys():\n",
    "    result += pred_dict[i]\n",
    "result=result/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission  =pd.read_csv(\"C:/Users/daisu/OneDrive/Desktop/GCI/drive-download-20201224T003704Z-001/sample_submission.csv\", index_col=0 )\n",
    "submission[\"units_sold_month\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"C:/Users/daisu/OneDrive/Desktop/GCI/drive-download-20201224T003704Z-001/submission_Auto_Gluon2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ModelExtractionCallback(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._model = None\n",
    "\n",
    "    def __call__(self, env):\n",
    "        # _CVBooster の参照を保持する\n",
    "        self._model = env.model\n",
    "\n",
    "    def _assert_called_cb(self):\n",
    "        if self._model is None:\n",
    "            # コールバックが呼ばれていないときは例外にする\n",
    "            raise RuntimeError('callback has not called yet')\n",
    "\n",
    "    @property\n",
    "    def boosters_proxy(self):\n",
    "        self._assert_called_cb()\n",
    "        # Booster へのプロキシオブジェクトを返す\n",
    "        return self._model\n",
    "\n",
    "    @property\n",
    "    def raw_boosters(self):\n",
    "        self._assert_called_cb()\n",
    "        # Booster のリストを返す\n",
    "        return self._model.boosters\n",
    "\n",
    "    @property\n",
    "    def best_iteration(self):\n",
    "        self._assert_called_cb()\n",
    "        # Early stop したときの boosting round を返す\n",
    "        return self._model.best_iteration\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  データセットを読み込む\n",
    "\n",
    "X, y = train_df, output\n",
    "\n",
    "# デモ用にデータセットを分割する\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# LightGBM 用のデータセット表現に直す\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "\n",
    "# 学習済みモデルを取り出すためのコールバックを用意する\n",
    "extraction_cb = ModelExtractionCallback()\n",
    "callbacks = [\n",
    "    extraction_cb,\n",
    "]\n",
    "\n",
    "# データセットを 5-Fold CV で学習する\n",
    "lgbm_params = {\n",
    "     #dart(drop out trees) often performs better\n",
    "    'objective': 'regression',\n",
    "    \"metric\": \"rmse\",\n",
    "     \"random_seed\": 0,\n",
    "     \"feature_pre_filter\": False,\n",
    "     \"lambda_l1\": 2.377982329588689e-07,\n",
    "     \"lambda_l2\":1.2825820088020978e-08,\n",
    "     \"num_leaves\": 256,\n",
    "     \"feature_fraction\": 0.6,\n",
    "     \"bagging_fraction\": 0.7471801931739468,\n",
    "     \"bagging_freq\": 7,\n",
    "     \"min_child_samples\": 5,\n",
    "}\n",
    "# NOTE: 一般的には返り値の内容 (交差検証の結果) を確認する\n",
    "lgb.cv(lgbm_params,\n",
    "        lgb_train,\n",
    "        num_boost_round=10,\n",
    "        early_stopping_rounds=10,\n",
    "        nfold=10,\n",
    "        shuffle=True,\n",
    "        stratified=True,\n",
    "        #seed=42,\n",
    "        callbacks=callbacks,\n",
    "        verbose_eval=1\n",
    "        )\n",
    "\n",
    "# コールバックのオブジェクトから学習済みモデルを取り出す\n",
    "proxy = extraction_cb.boosters_proxy\n",
    "boosters = extraction_cb.raw_boosters\n",
    "best_iteration = extraction_cb.best_iteration\n",
    "\n",
    "\n",
    "# # 各モデルで個別に推論する場合\n",
    "# pred_dict={}\n",
    "# for i, booster in enumerate(boosters):\n",
    "#     y_pred_proba = booster.predict(X_test,\n",
    "#                                     num_iteration=best_iteration)\n",
    "#     y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "#     pred_dict.setdefault(i, y_pred)\n",
    "#     accuracy = accuracy_score(y_test, y_pred) #正解率　全体に対して予測が当たった割合\n",
    "#     precision = precision_score(y_test, y_pred) #適合率 1と予測した中で実際にどれだけ1であったかの割合 ex)異常検知システムがアラートを出した回数のうち、実際に異常であった割合\n",
    "#     recall = recall_score(y_test, y_pred) #再現率 実際は1のデータのうち正しく1と予測できた割合 ex)病気の診断システムで再現率100%といった場合\n",
    "#     f1 =f1_score(y_test, y_pred)              #F1スコア 適合率と再現率の調和平均\n",
    "#     booster.feature_importances\n",
    "#     print(f'Model {i}\\n accuracy: {accuracy},\\n precision: {precision},\\n recall: {recall},\\n f1: {f1}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = lgb.LGBMClassifier(objective='binary',\n",
    "#                         num_leaves = 23,\n",
    "#                         learning_rate=0.1,\n",
    "#                         n_estimators=100,\n",
    "#                         boosting= \"dart\")\n",
    "\n",
    "# # 学習する\n",
    "# result = model.fit(X_train, y_train,\n",
    "#                    eval_set=[(X_test, y_test)],\n",
    "#                    eval_metric='multi_logloss'\n",
    "#                   )\n",
    "\n",
    "# # テストデータで予測する\n",
    "# y_pred = model.predict(X_test, num_iteration=result.best_iteration_)\n",
    "\n",
    "# # Accuracy を計算する\n",
    "# accuracy = sum(y_test == y_pred) / len(y_test)\n",
    "# print()\n",
    "# print(f\"accuracy: {accuracy}\")\n",
    "# print(f\"Precision: {precision_score(y_test, y_pred)}\") #適合率 1と予測した中で実際にどれだけ1であったかの割合 ex)異常検知システムがアラートを出した回数のうち、実際に異常であった割合\n",
    "# print(f\"Recall: {recall_score(y_test, y_pred)}\") #再現率 実際は1のデータのうち正しく1と予測できた割合 ex)病気の診断システムで再現率100%といった場合\n",
    "# print(f\"F1: {f1_score(y_test, y_pred)}\")             #F1スコア 適合率と再現率の調和平均\n",
    "\n",
    "# # importanceを表示する\n",
    "# importance = pd.DataFrame(model.feature_importances_, index=df.columns, columns=['importance'])\n",
    "# display(importance)\n",
    "# importance.plot.barh()\n",
    "\n",
    "\n",
    "\n",
    "# ## Optuna and Auto Hyperparameter tuning\n",
    "# import optuna.integration.lightgbm as lgb\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Set data as LGB\n",
    "# train = lgb.Dataset(X_train, y_train)\n",
    "# test  = lgb.Dataset(X_test, y_test)\n",
    "\n",
    "# # Hyper-parameter search\n",
    "# params = {\"objective\": \"regression\",\n",
    "#           \"metric\": \"rmse\"}\n",
    "\n",
    "\n",
    "# lgb_trained = lgb.train(params,\n",
    "#                         train, valid_sets=test,\n",
    "#                         early_stopping_rounds=100)\n",
    "\n",
    "# best_params = lgb_trained.params\n",
    "# print(\"Params:     \")\n",
    "# for key, value in best_params.items():\n",
    "#     print(f\"{key}: {value}\")\n",
    "\n",
    "\n",
    "# lgb.plot_importance(gbm)\n",
    "# lgb.create_tree_diagraph(gbm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
